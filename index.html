<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Investigations into hardware and software details">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Journey to the Center of the Computer</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="en" href="rss.xml">
<link rel="canonical" href="https://markdewing.github.io/blog/">
<link rel="next" href="index-1.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><link rel="prefetch" href="posts/2024/testing-scientific-software/" type="text/html">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-md static-top mb-4
navbar-dark
bg-dark
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href=".">

            <span id="blog-title">Journey to the Center of the Computer</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="categories/" class="nav-link">Tags</a>
                </li>
<li class="nav-item">
<a href="rss.xml" class="nav-link">RSS feed</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2024/testing-scientific-software/" class="u-url">Testing Scientific Software</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/2024/testing-scientific-software/" rel="bookmark">
            <time class="published dt-published" datetime="2024-04-25T11:20:00-05:00" itemprop="datePublished" title="2024-04-25 11:20">2024-04-25 11:20</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2024/testing-scientific-software/#disqus_thread" data-disqus-identifier="cache/posts/2024/testing-scientific-software.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>A perennial question when writing scientific code is how do you know the code is producing the right answer?</p>
<p>This post describes the <a href="https://github.com/QMCPACK/qmc_algorithms">QMC algorithms</a> repository and testing in QMCPACK development to provide some answers this question.
QMCPACK implements Quantum Monte Carlo (QMC) methods for solving the Schödinger equation for atoms, molecules, and solids.</p>
<p>The repository focuses on a few areas to contribute to testing and understanding scientific software:
1. Derived formulas using symbolic math
2. Code generation from symbolic math
3. Small problems with simple algorithms
4. Reproduce and explain papers</p>
<p>Another driving force in this work is that I have a strong conviction that symbolic mathematics is the most appropriate semantic level to describe scientific algorithms.
In this repository, Sympy is used for symbolic mathematics.</p>
<h3>Deriving formulas</h3>
<p>Some parts of scientific code are the final result of a series of derivation steps that are then
translated to code.  How do we know these steps are correct?  Especially the final step of math to code.
Usually these steps are all carried out by hand, with opportunities for errors to creep in.
We can use the computer to perform and check some of these steps.</p>
<h4>Computing derivatives for comparisons</h4>
<p>A Padé (rational function) form is the simplest functional form for a Jastrow factor, which describes electron-electron or electron-nucleus correlation in a wavefunction.
The <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Wavefunctions/Pade_Jastrow.ipynb">Pade_Jastrow.ipynb</a> notebook simply expresses the form, computes some derivatives, and evaluates them at a particular value.</p>
<p>The simplest way to use the results is to cut and paste the values from the notebook to the test case.
This gets tedious very quickly and is not easy to regenerate, especially when there are more
than a few values to copy.
It's straightforward to make a little template to output the values in a form
that is more directly usable in the test.</p>
<p>For example, the following Python code will output a line suitable for use in a C++ unit test (with <a href="https://github.com/catchorg/Catch2">Catch2</a> assertions).</p>
<div class="code"><pre class="code literal-block"><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">,</span><span class="n">r</span> <span class="o">=</span> <span class="n">symbols</span><span class="p">(</span><span class="s1">'A B r'</span><span class="p">)</span>
<span class="n">sym_u</span> <span class="o">=</span> <span class="n">A</span><span class="o">*</span><span class="n">r</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">B</span><span class="o">*</span><span class="n">r</span><span class="p">)</span> <span class="o">-</span> <span class="n">A</span><span class="o">/</span><span class="n">B</span>
<span class="n">val_u</span> <span class="o">=</span> <span class="n">u</span><span class="o">.</span><span class="n">subs</span><span class="p">({</span><span class="n">A</span><span class="p">:</span><span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">B</span><span class="p">:</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span><span class="mf">1.0</span><span class="p">})</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'CHECK(u == Approx(</span><span class="si">{</span><span class="n">val_u</span><span class="si">}</span><span class="s1">));'</span><span class="p">)</span>
</pre></div>

<h4>Other Derivations</h4>
<p>There are a few types of splines used in QMCPACK.</p>
<p>For <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Wavefunctions/Cubic%20Splines%20Basic.ipynb">cubic splines</a>, the notebook sets up the equations based on constraints and boundary conditions.
It computes an example and solve the equations using a dense linear solver. (An example of using a simpler algorithm for validation.  The real code uses a more efficient tridiagonal solver.)
This gets incorporated into QMCPACK tests with the script <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/Numerics/tests/gen_cubic_spline.py">gen_cubic_spline.py</a> and the output of that script is in <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/Numerics/tests/test_one_dim_cubic_spline.cpp">test_one_dim_cubic_spline.cpp</a>.</p>
<p>B-splines are used in a one-dimensional form for Jastrow electron-electron and electron-ion correlation factors.
And also in a three-dimensional form for representing single-particle periodic orbitals.
They are much faster to evaluate than a plane wave representation.
The <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Wavefunctions/Explain_Bspline.ipynb">Explain_Bspline.ipnyb</a> notebook starts from B-splines defined in Sympy and works through how they get used in QMCPACK.</p>
<h3>Code generation</h3>
<p>Code generation is used for the solver for the coefficients of cubic splines.
It starts from the tridiagonal matrix equations from Wikipedia, derives the cubic spline equations (same as previously), combines the two and outputs the resulting algorithm to C++ code.</p>
<p>The notebook is <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Wavefunctions/CubicSplineSolver.ipynb">CubicSplineSolver.ipynb</a>.
The corresponding script in QMCPACK is <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/Numerics/codegen/gen_cubic_spline_solver.py">gen_cubic_spline_solver.py</a>.
The generated spline solver is located in <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/Numerics/SplineSolvers.h">SplineSolvers.h</a>.</p>
<p>Some simpler code generation in the QMCPACK repository involves the angular part of atomic orbitals.<br>
There is a notebook about <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Wavefunctions/GaussianOrbitals.ipynb">Gaussian orbitals</a>.
In this case, the starting expression is simple and computing the various derivatives is tedious
and the script in QMCPACK, <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/Numerics/codegen/gen_cartesian_tensor.py">gen_cartesian_tensor.py</a>, takes care of that part.</p>
<h3>Simple algorithms</h3>
<p>Some ways to obtain reference values for test cases include special cases that have analytic solutions
and small problems that can be solved using an alternative method that is easier to understand and verify than the implemented algorithm.</p>
<p>Computing long-range sums of periodic Coulomb potentials requires some tricks to ensure convergence.
The Ewald method splits the sum in two pieces and uses the Fourier transform of the long-range part for faster convergence. It is implemented in a simple Python script, <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/LongRange/ewald_sum.py">ewald_sum.py</a>, which can be used to verify more sophisticated splits of the sum used in the code.</p>
<p>For the Schrödinger equation, an exact analytic solution is known for the hydrogen atom.
A deliberately incorrect wavefunction is used as a trial wavefunction in <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Variational/Variational_Hydrogen.ipynb">Variational_Hydrogen.ipynb</a> to demonstrate the variational principle.</p>
<p>A slightly larger problem is that of a helium atom.
The ground state wavefunction for a helium atom does not have an analytic solution and is the simplest example involving electron-electron correlation.
The notebook <a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Variational/Variational_Helium.ipynb">Variational_Helium.ipynb</a> uses symbolic means to find the derivatives of the local
energy, and grid-based integration instead of Monte Carlo.
(The details of the integration are discussed <a href="https://markdewing.github.io/blog/posts/integration-callbacks/">here</a>.)</p>
<p>Another approach to the derivatives is autodifferentiation.
There is a minimal QMC code used for creating reference values, particular for derivatives of variational parameters and orbital rotation.
It uses the <a href="https://github.com/HIPS/autograd">autograd</a> package for differentiation.
The QMC loop is in <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/QMCWaveFunctions/tests/run_qmc.py">run_qmc.py</a>.</p>
<p>The target systems are:
* Helium atom in <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/QMCWaveFunctions/tests/gen_rotated_lcao_wf.py">gen_rotated_lcao_wf.py</a>
* Beryllium atom in <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/QMCWaveFunctions/tests/rot_be_sto_wf.py">rot_be_sto_wf.py</a>
* Beryllium atom with two determinants in <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/QMCWaveFunctions/tests/rot_multi_be_sto_wf.py">rot_multi_be_sto_wf.py</a>
* Solid Beryllium with a psuedopotential in <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/QMCWaveFunctions/tests/eval_bspline_spo.py">eval_bspline_spo.py</a></p>
<p>(To improve on the performance of run_qmc.py and related scripts, I wrote a version using the multiprocessing package in Python. For even more performance, there is a port of these scripts to Julia.)</p>
<h3>Reproduce and explain papers</h3>
<p>Published papers contain derivations that leave intermediate steps as an exercise for the reader 
should they want to reproduce or implement the described algorithm.</p>
<p>There is a nice writeup, contributed by Andrew Baczewski, to explain and reproduce a paper <a href="https://journals.aps.org/pra/abstract/10.1103/PhysRevA.30.2713">"Observations on the statistical iteration of matrices"</a>
in this notebook
<a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/StochasticReconfiguration/Reproduce_Hetherington_PRA1984.ipynb">Reproduce Hetherington PRA1984.ipynb</a>
The paper describes a stochastic reconfiguration method for controlling variance and bias in a Monte Carlo simulation.</p>
<p>Another example involves a cusp correction scheme, which adds some modifications to Gaussian-type orbitals
commonly used in quantum chemistry to work better for a Quantum Monte Carlo wavefunction.
It comes from the paper 
<a href="https://doi.org/10.1063/1.1940588">Scheme for adding electron-nucleus cusps to Gaussian orbitals</a>.
The notebook
<a href="https://github.com/QMCPACK/qmc_algorithms/blob/master/Wavefunctions/CuspCorrection.ipynb">CuspCorrection.ipynb</a>
follows through solving some polynomial equations and presents some examples.
The script used to generate reference values for tests in QMCPACK is <a href="https://github.com/QMCPACK/qmcpack/blob/develop/src/QMCWaveFunctions/tests/gen_cusp_corr.py">gen_cusp_corr.py</a>.</p>
<p>The process for using notebooks is
1. Jupyter notebook provides exposition of an algorithm or concept.
2. The code gets copied to a script in the appropriate test directory in the
QMCPACK repository, and that location is the code that produces the results for the QMCPACK tests.</p>
<p>This does result in duplication of code, but at least the scripts and tests in the QMCPACK repository are self-contained.</p>
<h3>Final thoughts</h3>
<p>This post described several techniques for testing scientific software.</p>
<p>One of the important aspects of learning is working with the material and wrestling with it.
At some point, you have to do the derivation yourself in order to learn it.
These notebooks are a record of my approach to exploring these topics.
Are these useful to anyone else? Could they be made more useful?</p>
<p>The descriptions in many of the notebooks are very short and could be expanded.
What would make them more useful?  For someone trying to understand
the code?  Or for someone trying to reproduce and extend the work?</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2023/my-github-repos/" class="u-url">Guide to my Github Repositories</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/2023/my-github-repos/" rel="bookmark">
            <time class="published dt-published" datetime="2023-11-06T00:08:02-05:00" itemprop="datePublished" title="2023-11-06 00:08">2023-11-06 00:08</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2023/my-github-repos/#disqus_thread" data-disqus-identifier="cache/posts/2023/my-github-repos.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>This post is a short guide to my Github repositories.</p>
<p>Some of them I use as a wiki for keeping information.
Markdown makes adding and editing text easy, and it can also contain code.</p>
<p>Other repositories have more code to explore a particular topic.  I should expand on some of these topics in future blog posts. 
(Especially the contents and use of the "QMC Algorithms" repository.
It's used as a base for creating validated unit test data for <a href="https://github.com/QMCPACK/qmcpack">QMCPACK</a>, and it's a direction I think more projects should move towards.)</p>
<h3>Wiki-like Information</h3>
<p><a href="https://github.com/markdewing/GPU_internals">GPU Internals</a> - Documentation on how GPUs work and programming models</p>
<p><a href="https://github.com/markdewing/ML_in_scientific_computation">ML in scientific computation</a> - Machine learning and scientific computation</p>
<h3>Programming Ideas</h3>
<p><a href="https://github.com/markdewing/next_steps_in_programming">Next Steps in Programming</a> - Ideas on programming scientific applications.  Includes a focus on code changes a first class/primary object in programming.</p>
<p><a href="https://github.com/markdewing/programming_tutorial_maker">Programming Tutorial Maker</a> - Attempt at a tool to make writing incremental tutorials easier.</p>
<h3>Scientific Computing</h3>
<p><a href="https://github.com/markdewing/qmc_algorithms">QMC Algorithms</a> - Scripts, Jupyter notebooks, Sympy derivations, and code generation to support validating QMC codes. (Also <a href="https://github.com/QMCPACK/qmc_algorithms">here</a>)</p>
<p><a href="https://github.com/markdewing/qmc_kernels">QMC Kernels</a> - Kernels used in Quantum Monte Carlo in general, and QMCPACK in particular.  Also some simple kernels used to explore GPU offload programming models.</p>
<p><a href="https://github.com/markdewing/small_molecules">Small Molecules</a> - Example input files for quantum chemistry packages and information on various small molecules.</p>
<p><a href="https://github.com/markdewing/crispy-quadrature">Quadrature</a> - Multidimensional quadrature algorithms. (Technically "cubature").  In addition to notes and links, this has some implementations.</p>
<p><a href="https://github.com/markdewing/silver-floating-point">Floating point</a> - Floating point arithmetic.  Particularly for exploring low precision.
(the 'silver' part of the repository name comes from Github's initial repository name suggestion)</p>
<p><a href="https://github.com/markdewing/derivative_code_gen">Symbolic Derivatives with Code Generation</a> Represents scientific computations using Sympy. It can take derivatives symbolically, then code generate the result to Python, Julia or C++.</p>
<p><a href="https://github.com/markdewing/multitevo">Multitevo</a> Translation of CoMD molecular dynamics miniapp to other languages, such as Python and Julia. And Javascript, should I get it checked-in and pushed.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/2018/bash_for_c_programmers/" class="u-url">Bash for C programmers</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/2018/bash_for_c_programmers/" rel="bookmark">
            <time class="published dt-published" datetime="2018-07-10T16:41:01-05:00" itemprop="datePublished" title="2018-07-10 16:41">2018-07-10 16:41</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/2018/bash_for_c_programmers/#disqus_thread" data-disqus-identifier="cache/posts/2018/bash_for_c_programmers.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <h2>Bash scripting</h2>
<p>Why use Bash?  It is not my preferred language, but it has two big advantages:</p>
<ul>
<li>Availability - we can safely assume bash is present everywhere.  No need to install additional software.</li>
<li>Ease of starting and incremental building - a script can start as a small list of commands and grow incrementally.</li>
</ul>
<p>The rest of this post not a tutorial, but some ways to think about bash scripting in order to avoid common traps when coming from C/C++ or Python.</p>
<h3>Quick Intro</h3>
<h4>Whitespace is significant</h4>
<p>Almost everything in bash is a command with arguments. After all the substitutions and quoting, the basic structure of each line is a command with all its arguments are separated by whitespace.  This makes whitespace significant in ways that can be confusing when coming from other languages.</p>
<p>One place this shows up is in setting variables - there should be no whitespace on either side of the equal sign.
The statement <code>a = 1</code> will fail with an error about 'a' not found - the shell interprets it as a command.
Similarly <code>a= 1</code> will fail with an error about '1' not found.</p>
<p>Another place significant whitespace appears is in <code>if</code> statements.
The opening bracket for the test (<code>[</code>) looks like syntax, but it is a command.  (By symmetry you might expect <code>]</code> to be a command, but it's not - it gets passed as an argument to <code>[</code>).</p>
<div class="code"><pre class="code literal-block"><span class="nv">a</span><span class="o">=</span><span class="m">0</span>
<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$a</span><span class="w"> </span>-eq<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s2">"a is 0"</span>
<span class="k">fi</span>
</pre></div>

<p>Also note the semicolon after the comparison to terminate the command.  As an alternative, the <code>then</code> could be put on the next line</p>
<div class="code"><pre class="code literal-block"><span class="nv">a</span><span class="o">=</span><span class="m">0</span>
<span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="nv">$a</span><span class="w"> </span>-eq<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="o">]</span>
<span class="k">then</span>
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s2">"a is 0"</span>
<span class="k">fi</span>
</pre></div>

<p>Bash also has a double bracket form of testing that is a built-in, and not an external command.</p>
<h4>Exit values</h4>
<p>Exit values from commands are 'success' or 'failure'.  Tests of the exit value, like the 'if' statement or the control operators (<code>&amp;&amp;</code> and <code>||</code>) operate on these exit values (and only exit values).
Numerically, success maps to 0, whereas failure maps to a non-zero value.
This numerical mapping is opposite of many other languages, like C/C++ and Python, where 0 is false and non-zero values are true.
Using multiple values for failure can give some indication of what went wrong with the command.</p>
<p>The best way to think about this is not to mentally reverse the values, but to think in terms of 'success' and 'failure', and only think about the numerical mapping if necessary.</p>
<p>Sequencing and control operator idioms:</p>
<ul>
<li>
<code>A;B</code>  Run A and then B, regardless of success of A</li>
<li>
<code>A &amp;&amp; B</code> Run B if A succeeded</li>
<li>
<code>A || B</code> Run B if A failed</li>
<li>
<code>A &amp;</code> Run A in the background</li>
</ul>
<p>( from <a href="https://unix.stackexchange.com/questions/24684/confusing-use-of-and-operators">https://unix.stackexchange.com/questions/24684/confusing-use-of-and-operators</a> )</p>
<h4>Functions</h4>
<p>Functions start with "<code>function</code> <em>name</em> <code>{</code>" or "<em>name</em>  <code>() {</code>".
The body is a series of commands, and the function ends with <code>}</code>.
Once again, whitespace is significant.  The function declaration should be on a line by itself,
and the closing brace should also be on a line by itself.</p>
<p>A function call looks like a normal command statement, with the usual space-separated arguments.</p>
<p>Inside a function, arguments are referenced using <code>$1</code>, <code>$2</code>, etc.  Unset variables are empty.</p>
<p>There is a syntax for optional arguments:</p>
<div class="code"><pre class="code literal-block"><span class="nv">var</span><span class="o">=</span><span class="si">${</span><span class="nv">1</span><span class="k">:-</span><span class="nv">default_string_here</span><span class="si">}</span>
</pre></div>

<h4>Variable replacement</h4>
<p>Variable replacement occurs <em>before</em> bash breaks the line into a command and arguments based on whitespace.
Unexpected behavior can happen if a variable contains whitespace and the developer was not expecting it.
This can happen when the variable holds a directory name, and the script is run using a directory containing a space.</p>
<div class="code"><pre class="code literal-block"><span class="nv">a</span><span class="o">=</span><span class="s2">"hi there"</span>
cmd<span class="w"> </span><span class="nv">$a</span>
</pre></div>

<p>expands to calling <code>cmd</code> with two arguments 'hi' and 'there'.
Enclose the variable in quotes to keep spaces confined.</p>
<p>This will call <code>cmd</code> with one argument: 'hi there'.</p>
<div class="code"><pre class="code literal-block"><span class="nv">a</span><span class="o">=</span><span class="s2">"hi there"</span>
cmd<span class="w"> </span><span class="s2">"</span><span class="nv">$a</span><span class="s2">"</span>
</pre></div>

<p>For a gory step-by-step look at how bash processes input, see <a href="https://mywiki.wooledge.org/BashParser">https://mywiki.wooledge.org/BashParser</a></p>
<h4>Robust bash scripts</h4>
<p>See <a href="https://www.davidpashley.com/articles/writing-robust-shell-scripts/">https://www.davidpashley.com/articles/writing-robust-shell-scripts/</a> for advice on writing robust scripts.</p>
<p>Part of the advice is to use these settings</p>
<ul>
<li>
<code>set -o nounset</code>  to detect the use of uninitialized variables</li>
<li>
<code>set -o errexit</code>  to exit the script if any statement fails</li>
</ul>
</div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/building-a-parallella-cluster/" class="u-url">Building A Parallella Cluster</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/building-a-parallella-cluster/" rel="bookmark">
            <time class="published dt-published" datetime="2017-01-02T20:56:00-05:00" itemprop="datePublished" title="2017-01-02 20:56">2017-01-02 20:56</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/building-a-parallella-cluster/#disqus_thread" data-disqus-identifier="cache/posts/building-a-parallella-cluster.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>I finally got around to assembling my small pile of Parallella boards into a cluster.</p>
<p><a href="2016/parallella_cluster_side_top_lg.jpg"><img alt="Alternate side view" src="2016/parallella_cluster_side_top_sm3.jpg"></a></p>
<p>This post documents the choices I made about power distribution, mechanical assembly, cooling, software management, etc.
For background on the individual boards, see my previous post:
<a href="https://markdewing.github.io/blog/posts/introduction-to-parallella/">Introduction to Parallella</a>.</p>
<p>The software directions are based on the Linaro 14.04 image.
(At some point I should upgrade to the latest Paraubuntu release.)</p>
<h3>Power</h3>
<p>There are several options for powering multiple boards:</p>
<ol>
<li>Solder a jumper and use the mounting pads with metal standoffs to transmit the power.  This option requires the fewest cords.</li>
<li>Use micro USB connector (need to switch jumper J14).  There are multi-port USB power supplies that should work.  This is probably the simplest option for a small number of boards.</li>
<li>Use the 5.5mm barrel plug (default settings).  There are versions with screw terminals on Amazon (<a href="https://www.amazon.com/gp/product/B00VESYK0S/">these</a> for example).</li>
</ol>
<p>I went with option 3 and used an old PC power supply for the power.</p>
<h3>Mechanical assembly</h3>
<p>I used <a href="https://www.amazon.com/gp/product/B013G1Q300/">20mm nylon standoffs</a> and assembled the boards into two stacks.
A small piece of 1/4" plywood was used for the base.</p>
<h3>Cooling</h3>
<p>For air flow, I used a cooling fan from an old PC and mounted it to the plywood base.</p>
<h3>Network</h3>
<p>Needing ports for a maximum of 10 boards, plus one port for the external connection, I chose a <a href="https://www.amazon.com/gp/product/B0092KZBCQ/">16-port Gigabit D-Link switch</a>.
Eventually I would like to power the network switch from the PC power supply, but need to get the right plug first.</p>
<p>The nodes use DHCP from my home network get their addresses.
A future improvement is to run a DHCP server on one node and use that to supply addresses to the other nodes.
This would make the cluster independent of running on my home network.</p>
<h3>MicroSD cards</h3>
<p>Follow the directions on the Parallella <a href="http://www.parallella.org/create-sdcard/">Create SD Card</a> page.
After burning the image, use <code>gparted</code> to resize the partition to the full capacity of the card.</p>
<h3>Management and control</h3>
<p>Performing software installs and other management on all of boards individually would be too tedious.
There are many solutions for managing clusters.
I decided to use <a href="http://docs.ansible.com/ansible/intro_getting_started.html">Ansible</a>, as it seemed the simplest (no software needed on nodes) and it runs over ssh.</p>
<p>In addition to controlling operations from a PC, it is useful to designate one node as a 'head node' and install Ansible there as well.
For MPI, it's easier to run MPI programs from the head node than from the PC.
For setting up configuration files, it can be useful to create or edit the file and make sure it works on one node, and then copy the file to all the other nodes.</p>
<p>Ansible and MPI (and general convenience) require setting up <a href="http://www.tecmint.com/ssh-passwordless-login-using-ssh-keygen-in-5-easy-steps/">passwordless ssh login</a>.</p>
<!--Some directions to set up [ssh passwordless login](http://www.tecmint.com/ssh-passwordless-login-using-ssh-keygen-in-5-easy-steps/)-->

<p>Once the keys are set up locally, you can use <code>ssh-copy-id</code> to copy the credentials.</p>
<div class="code"><pre class="code literal-block"><span class="n">ssh</span><span class="o">-</span><span class="k">copy</span><span class="o">-</span><span class="kt">id</span><span class="w"> </span><span class="o">-</span><span class="n">i</span><span class="w"> </span><span class="o">~/</span><span class="p">.</span><span class="n">ssh</span><span class="o">/</span><span class="n">id_rsa</span><span class="p">.</span><span class="n">pub</span><span class="w"> </span><span class="n">parallella</span><span class="mf">@10.0.0.145</span>
</pre></div>

<p>I keep a small script that puts this line in the history (named <code>ssh_copy_id</code>)</p>
<div class="code"><pre class="code literal-block"><span class="n">history</span><span class="w"> </span><span class="o">-</span><span class="n">s</span><span class="w"> </span><span class="s">"ssh-copy-id -i ~/.ssh/id_rsa.pub parallella@10.0.0.145"</span>
</pre></div>

<p>Run the command <code>source ssh_copy_id</code> to put the command on the history list.
Use the bash history and line editing features to select the command and update to a new address.</p>
<p>Rather than create a new user, I'm using the default 'parallella' user on the nodes.
The SSH config (in '.ssh/config') can be set up to switch users upon login.</p>
<div class="code"><pre class="code literal-block">Host 10.0.0.127
    User parallella
</pre></div>

<p>You might wish to <a href="http://www.tecmint.com/apt-cache-server-in-ubuntu/">set up a apt-cache server</a> on a local machine to save on download bandwidth when installing software to all the nodes.</p>
<!--[Some directions here](http://www.tecmint.com/apt-cache-server-in-ubuntu/)-->

<h4>Using Ansible</h4>
<p>See the <a href="http://docs.ansible.com/ansible/intro_getting_started.html">intro docs</a>.</p>
<p>The inventory file is a list of IP addresses (one per line).     It can be specified on the command line
with `-i'.  To see if all the nodes work</p>
<div class="code"><pre class="code literal-block">ansible -i cluster.ini all -m ping
</pre></div>

<p>To copy the apt-cache server configuration to all the nodes, use</p>
<div class="code"><pre class="code literal-block"> ansible -i hosts all --sudo -m copy -a "src=/etc/apt/apt.conf.d/02proxy dest=/etc/apt/apt.conf.d/02proxy"
</pre></div>

<p>To shutdown all the nodes, use</p>
<div class="code"><pre class="code literal-block">ansible -i cluster.ini all --sudo -m shell -a "shutdown now"
</pre></div>

<h3>Compilation</h3>
<p>In the <a href="https://markdewing.github.io/blog/posts/introduction-to-parallella/">introductory post</a> I talked about cross compiling for the board.
That gets more complicated with larger software packages.
For instance, one of my project dependencies, HDF, doesn't cross-compile easily (or at all). </p>
<p>Since the nodes use a regular Ubuntu distribution, native compilation is easy, but slow.</p>
<p>One solution is to use <a href="https://github.com/distcc/distcc">distcc</a>.  </p>
<p>The particular software package I'm working with (QMCPACK, which does simulations on atoms, molecules, and solids)
uses CMake for configuration and build, and builds fine with distcc.</p>
<p>Install on all nodes with </p>
<div class="code"><pre class="code literal-block">ansible -i cluster.ini all --sudo  -a "apt-get install -y distcc"
</pre></div>

<p>Set the <code>DISTCC_HOSTS</code> variable to the set of systems to use</p>
<div class="code"><pre class="code literal-block"><span class="n">export</span><span class="w"> </span><span class="n">DISTCC_HOSTS</span><span class="o">=</span><span class="s">"localhost @10.0.0.144/2 @10.0.0.145/2"</span>
</pre></div>

<p>This example shows three hosts. The initial '@' means to use ssh (no daemon required on remote) and the '/2' on the end means to use two threads.</p>
<p>Now set the C and C++ compilers to <code>distcc &lt;compiler&gt;</code> and run the build.</p>
<p>For CMake, building a project with MPI, this is</p>
<div class="code"><pre class="code literal-block"><span class="k">export</span><span class="w"> </span><span class="n">CC</span><span class="o">=</span><span class="s2">"distcc mpicc"</span>
<span class="k">export</span><span class="w"> </span><span class="n">CXX</span><span class="o">=</span><span class="s2">"distcc mpic++"</span>
</pre></div>

<p>Then</p>
<div class="code"><pre class="code literal-block">make -j 8
</pre></div>

<p>You might see an warning message </p>
<div class="code"><pre class="code literal-block">distccd[&lt;pid&gt;] (tcp_cork_sock) Warning: setsockopt(corked=1) failed: Socket operation on non-socket
</pre></div>

<p>This can be ignored.  Or follow some directions to <a href="https://jeffreywildman.wordpress.com/2011/02/11/disable-tcp_cork_sock-warnings-when-using-distcc-over-ssh/">silence it</a>.</p>
<h3>MPI</h3>
<p>One popular method for writing programs that communicate across the boards is <a href="https://computing.llnl.gov/tutorials/mpi/">MPI (Message Passing Interface)</a>.</p>
<p>Install the 'mpi-default-dev' package (which should also install the 'mpi-default-bin' package).
This installs the Open MPI implementation (the alternative being MPICH).
Note that this MPI is only concerned with communication between the ARM cores on different boards.
There is also the Brown Deer Technology version of MPI for programming the Epiphany accelerator.</p>
<p>It's common to use a networked file system so each local node has access to the executables and input files.
Ansible has file distribution commands that work well enough that a networked file system isn't strictly necessary.
(Be aware when copying directories with Ansible that if the directory specified in <code>src</code> does not end with '/', the directory and it's contents are copied.  If it does end with '/', just the directory contents are copied.)</p>
<p>Open MPI uses a tree-based launcher for better scalable start-up performance.  Because of this, each node should
be able to log into each other node (not just head node to other nodes).</p>
<p>MPI needs a list of machines to run on.  One method is to create a host file and pass it to <code>mpirun</code> with the <code>--hostfile</code> option.  The host file, at its simplest, is one hostname or IP address per line (same as a simple Ansible inventory file.)</p>
<h3>Gallery</h3>
<p><a href="2016/parallella_cluster_front_side_lg.jpg"><img alt="Front/side view" src="2016/parallella_cluster_front_side_sm2.jpg"></a>    
<a href="2016/parallella_cluster_back_view_lg.jpg"><img alt="Back view" src="2016/parallella_cluster_back_view_sm2.jpg"></a>   </p>
<p><a href="2016/parallella_cluster_side_lg.jpg"><img alt="Side view" src="2016/parallella_cluster_side_sm2.jpg"></a>   
<a href="2016/parallella_cluster_top_lg.jpg"><img alt="Top view" src="2016/parallella_cluster_top_sm2.jpg"></a>  
<a href="2016/parallella_cluster_side_top_lg.jpg"><img alt="Alternate side view" src="2016/parallella_cluster_side_top_sm3.jpg"></a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/integration-callbacks/" class="u-url">Integration Callbacks with Sympy and LLVM</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/integration-callbacks/" rel="bookmark">
            <time class="published dt-published" datetime="2016-07-08T16:37:00-05:00" itemprop="datePublished" title="2016-07-08 16:37">2016-07-08 16:37</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/integration-callbacks/#disqus_thread" data-disqus-identifier="cache/posts/integration_callbacks.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>This post explores various packages for multi-dimensional integration along with
generating callbacks for the integrands from Sympy using an LLVM JIT</p>
<h3>Problem to integrate</h3>
<p>The particular problem is using the variational principle to find the ground state energy for atoms.
Some Jupyter notebooks with a description of the problem, along with various integration methods:</p>
<p><a href="https://github.com/markdewing/next_steps_in_programming/blob/master/examples/integration/Hydogen%20Atom.ipynb">Ground state energy of Hydrogen Atom</a>   (This yields a 3 dimensional integral.)</p>
<p><a href="https://github.com/markdewing/next_steps_in_programming/blob/master/examples/integration/Helium%20atom.ipynb">Ground state energy of Helium Atom</a>  (This yields a 6 dimensional integral.)</p>
<p>The standard solution to these integrals is to use Markov Chain Monte Carlo (the Quantum Monte Carlo method).<br>
However, I'm curious to see how far alternate integration schemes or existing integration packages would work.</p>
<h3>Integration libraries</h3>
<p>The <a href="http://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html">scipy quadrature</a> routines accept a natively compiled callback for the integrand. 
(Noticing this in the documentation initiated the idea for using JIT compilation for callback functions.)</p>
<p>Next up is the <a href="http://ab-initio.mit.edu/wiki/index.php/Cubature">Cubature</a> integration package, with the <a href="https://github.com/saullocastro/cubature">Python wrapper for cubature</a></p>
<p>Finally is the <a href="http://www.feynarts.de/cuba/">Cuba</a> library, with the PyCuba interface (part of the <a href="https://github.com/JohannesBuchner/PyMultiNest">PyMultiNest</a> package)</p>
<p>There are some other libraries such at <a href="http://mint.sbg.ac.at/HIntLib/">HIntLib</a> that I would also like to try.  There doesn't seem to be a python interface for HIntLib.  Let me know if there is one somewhere. And if there are other multidimensional integration packages to try.</p>
<h3>Evaluating the integrand</h3>
<p>One of my scientific programming goals is to generate efficient code from a symbolic expression.
To this end, I've been working on an LLVM JIT converter for Sympy expressions (using the <a href="https://github.com/numba/llvmlite">llvmlite</a> wrapper).</p>
<p>For the Sympy code, see these pull requests: </p>
<ul>
<li>
<a href="https://github.com/sympy/sympy/pull/10451">Create executable functions from Sympy expressions</a> </li>
<li><a href="https://github.com/sympy/sympy/pull/10640">Accelerated callbacks for integration routines</a></li>
<li><a href="https://github.com/sympy/sympy/pull/10683">JIT - handle multiple expressions (as returned from CSE)</a></li>
<li><a href="https://github.com/sympy/sympy/pull/11057">Add LLVM JIT callbacks for PyCuba integration</a></li>
</ul>
<p>As an aside, one can question if is this the right approach, compared with</p>
<ol>
<li>Generate C++ or Fortran and compile using the existing autowrap functionality in Sympy.</li>
<li>Generate Python/Numpy and use Numba.</li>
<li>Use Julia</li>
</ol>
<p>There is always a tradeoff between a narrow, specialized solution, which is faster to implement and
perhaps easier to understand, and a more general solution, which applies in more cases, but is
harder and slower to implement.</p>
<p>Using an LLVM JIT is a specialized solution, but it does have an advantage that there is a short path from the expressions to the compiled code.
One disadvantage is that it does not leverage existing compilers (Numba or C++), though LLVM compiler optimization passes are available.</p>
<p>Sometimes a solution just needs to be tried to gain experience with the advantages and drawbacks.</p>
<h3>Results</h3>
<p>For the helium atom, the integration times are reported in the table below</p>
<table>
<thead><tr>
<th style="text-align: left;">Integrator  </th>
<th style="text-align: right;">Time (seconds)</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align: left;">Cubature</td>
<td style="text-align: right;">171</td>
</tr>
<tr>
<td style="text-align: left;">Cubature w/CSE</td>
<td style="text-align: right;">141</td>
</tr>
<tr>
<td style="text-align: left;">Cubature w/CSE and multiple evals</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td style="text-align: left;">Cuba (Vegas)</td>
<td style="text-align: right;">29</td>
</tr>
<tr>
<td style="text-align: left;">Cuba (Cuhre)</td>
<td style="text-align: right;">22</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>Note that <code>scipy.nquad</code> was not used for the 6D integral. It quickly runs out of steam because it consists of iterated one dimensional integrations, and the glue between the dimensions goes through Python, reducing the effectiveness of a compiled integrand.</p>
<p>The Cubature library does better.  Profiling shows that most of the time is spent internal to cubature and allocating memory, so faster integrand evaluation is not going to improve the time.
Some other approaches can help.  One is Common Subexpression Elimination (CSE), which Sympy can perform on the expression.  This extracts duplicate fragments so their value only needs to be computed once.</p>
<p>The library also allows multiple integrals to be performed at once.   This can amortize some of the overhead of the library.  In this case, the individual calls to integrator for the numerator and denominator can be reduced to a single call.</p>
<p>The Cuba library performs even better, as there is apparently less overhead inside the integration library.  The Cuhre integrator uses a deterministic grid-based algorithm similar to Cubature.  Vegas uses an adaptive Monte Carlo approach.</p>
<p>The results are not shown here, but I also used SIMD vectorization to make the function evaluation even faster, which succeeded for the bare function evaluation. (This was one of the original motivations for compiling straight to LLVM, as it would be easier to get vectorization working.)
 Unfortunately, it did not speed up the overall integration much (if at all), due to overhead in the libraries.</p>
<h3>Conclusions and future work</h3>
<p>Using an LLVM JIT to create callbacks for integration works fairly well.</p>
<p>One important question is how to scale the creation of the callbacks to new libraries without explicitly programming them into Sympy.<br>
The <a href="https://github.com/sympy/sympy/pull/11057">last pull request</a> has expanded the <code>CodeSignature</code> class, which seems like  a starting point for such a more general callback specification.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/notes-on-cmake/" class="u-url">Notes on CMake</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/notes-on-cmake/" rel="bookmark">
            <time class="published dt-published" datetime="2016-02-19T05:05:00-06:00" itemprop="datePublished" title="2016-02-19 05:05">2016-02-19 05:05</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/notes-on-cmake/#disqus_thread" data-disqus-identifier="cache/posts/notes-on-cmake.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>Recently I started working on a project that uses CMake.  I've used CMake a little before, but never really
had to dive much into it.
In particular, I needed to understand the scripting parts of CMake for adding tests for CTest.</p>
<p>Below are some comments on aspects of CMake.</p>
<h3>Variables and variable substitution</h3>
<p>Variables names are strings.  Substitution occurs when the variable is dereferenced with <code>${}</code>.</p>
<div class="code"><pre class="code literal-block"><span class="nb">SET</span><span class="p">(</span><span class="s">var,</span><span class="w"> </span><span class="s">a</span><span class="p">)</span>
<span class="nb">MESSAGE</span><span class="p">(</span><span class="s2">"var = ${var}"</span><span class="p">)</span>
</pre></div>

<p>produces</p>
<div class="code"><pre class="code literal-block"><span class="k">var</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span>
</pre></div>

<p>Nested substitutions are possible</p>
<div class="code"><pre class="code literal-block"><span class="nb">SET</span><span class="p">(</span><span class="s">var,</span><span class="w"> </span><span class="s">a</span><span class="p">)</span>
<span class="nb">SET</span><span class="p">(</span><span class="s">a,</span><span class="w"> </span><span class="s">b</span><span class="p">)</span>
<span class="nb">MESSAGE</span><span class="p">(</span><span class="s2">"var = ${var}  ${${var}}"</span><span class="p">)</span>
</pre></div>

<p>will produce 
<code>var = a b</code></p>
<p>Variable names can be composed during substitution</p>
<div class="code"><pre class="code literal-block"><span class="nb">SET</span><span class="p">(</span><span class="s">var,</span><span class="w"> </span><span class="s">a</span><span class="p">)</span>
<span class="nb">SET</span><span class="p">(</span><span class="s">a_one,</span><span class="w"> </span><span class="s">apple</span><span class="p">)</span>
<span class="nb">MESSAGE</span><span class="p">(</span><span class="s2">"var =  ${${var}_one}"</span><span class="p">)</span>
</pre></div>

<p>will produce <code>var = apple</code></p>
<h3>Variables and functions</h3>
<p>Variable references act a little like pointers, but without a type system to enforce (and guide) how many indirections should be performed.</p>
<p>Example of using a variable inside a function:</p>
<div class="code"><pre class="code literal-block"><span class="nb">FUNCTION</span><span class="p">(</span><span class="s">MY_FUNC</span><span class="w"> </span><span class="s">arg1</span><span class="p">)</span>
<span class="w">    </span><span class="nb">MESSAGE</span><span class="p">(</span><span class="s2">"arg1 = ${arg1}"</span><span class="p">)</span>
<span class="nb">ENDFUNCTION</span><span class="p">()</span>

<span class="nb">MY_FUNC</span><span class="p">(</span><span class="s">hello</span><span class="p">)</span>
<span class="nb">SET</span><span class="p">(</span><span class="s">var,</span><span class="w"> </span><span class="s">a</span><span class="p">)</span>
<span class="nb">MY_FUNC</span><span class="p">(</span><span class="s">var</span><span class="p">)</span><span class="w"> </span><span class="c"># arg1 is set to 'var'</span>
<span class="nb">MY_FUNC</span><span class="p">(</span><span class="o">${</span><span class="nv">var</span><span class="o">}</span><span class="p">)</span><span class="w"> </span><span class="c"># arg1 is set to 'a' - this is usually what you want</span>
</pre></div>

<p>produces</p>
<div class="code"><pre class="code literal-block"><span class="n">arg1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">var</span>
<span class="n">arg1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span>
</pre></div>

<h3>Return values from functions</h3>
<p>There is no built-in notion of a return value from a function.   To get values out of a function, write to one of the arguments.</p>
<p>A function creates a new scope - changes to a variable will only affect the variable's value 
inside the function.  To affect the value in the parent, the <code>PARENT_SCOPE</code> modifier should be given to the <code>SET</code> command.  (More on variable scopes <a href="https://www.johnlamp.net/cmake-tutorial-5-functionally-improved-testing.html">here</a>)</p>
<p>Another issue is the variable name for the output value needs to be dereferenced before being set.
Otherwise a variable with the name used in the function will be set in the parent, which can work by accident
if the variables have the same name.</p>
<p>Example:</p>
<div class="code"><pre class="code literal-block"><span class="nb">FUNCTION</span><span class="p">(</span><span class="s">MY_FUNC_WITH_RET</span><span class="w"> </span><span class="s">ret</span><span class="p">)</span>
<span class="w">    </span><span class="c"># The following line works by accident if the name of variable in the parent</span>
<span class="w">    </span><span class="c"># is the same as in the function</span>
<span class="w">    </span><span class="nb">SET</span><span class="p">(</span><span class="s">ret</span><span class="w"> </span><span class="s2">"in function"</span><span class="w"> </span><span class="s">PARENT_SCOPE</span><span class="p">)</span>
<span class="w">    </span><span class="c"># This is the correct way to get the variable name passed to the function</span>
<span class="w">    </span><span class="nb">SET</span><span class="p">(</span><span class="o">${</span><span class="nv">ret</span><span class="o">}</span><span class="w"> </span><span class="s2">"in function"</span><span class="w"> </span><span class="s">PARENT_SCOPE</span><span class="p">)</span>
<span class="nb">ENDFUNCTION</span><span class="p">()</span>

<span class="nb">SET</span><span class="p">(</span><span class="s">ret</span><span class="w"> </span><span class="s2">"before function"</span><span class="p">)</span>
<span class="nb">MY_FUNC_WITH_RET</span><span class="p">(</span><span class="s">ret</span><span class="p">)</span>
<span class="nb">MESSAGE</span><span class="p">(</span><span class="s2">"output from function = ${ret}"</span><span class="p">)</span>
</pre></div>

<p>will produce <code>output from function = in function</code></p>
<h3>Data structures</h3>
<p>There is only the List type, with some functions for operations on lists.
The <a href="https://cmake.org/cmake/help/v3.3/manual/cmake-language.7.html#lists">documentation on lists</a> says that "Lists ... should not be used for complex data processing tasks", but doesn't say what to use instead.</p>
<p>For associative arrays or maps there are some options:</p>
<ul>
<li>Two parallel lists - one of keys and one of values.  Search the key list and use the index to look up value.  More awkward for passing to functions.</li>
<li>Single list with alternating keys and values.  Search the list for the key, and use index+1 to look up the value.  Only works if the range of possibilities for keys and values are distinct (e.g., keys are strings and values are always numbers).</li>
<li>The environment (<code>ENV{key}</code>) is a built-in associative array.  It could be overloaded to store other values, at the risk of polluting the environment.</li>
</ul>
<h3>Test timeout</h3>
<p>The default timeout per test is 1500 seconds (25 minutes).</p>
<p>To increase this, adjust the value of <code>DART_TESTING_TIMEOUT</code>.
It needs to be set as a cache variable, and it needs to be set before the <code>enable_testing()</code> or <code>include(CTest)</code> is specified.</p>
<div class="code"><pre class="code literal-block"><span class="nb">SET</span><span class="p">(</span><span class="w"> </span><span class="s">DART_TESTING_TIMEOUT</span><span class="w"> </span><span class="s">3600</span><span class="w"> </span><span class="s">CACHE</span><span class="w"> </span><span class="s">STRING</span><span class="w"> </span><span class="s2">"Maximum time for one test"</span><span class="p">)</span>
</pre></div>

<p>See also this <a href="http://stackoverflow.com/questions/3545598/using-cmake-with-ctest-and-cdash">Stack Overflow post</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/visualizing-md-data/" class="u-url">Visualizing MD Data</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/visualizing-md-data/" rel="bookmark">
            <time class="published dt-published" datetime="2015-12-08T22:14:00-06:00" itemprop="datePublished" title="2015-12-08 22:14">2015-12-08 22:14</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/visualizing-md-data/#disqus_thread" data-disqus-identifier="cache/posts/visualizing-md-data.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>Visualizing atomic positions in 3D is useful when working on a molecular dynamics code.</p>
<p>More generally, being able to visualize the structures and algorithms inside a code can help with understanding
and debugging.
With all the advances in graphics hardware, it should be possible to quickly create visualizations for various
aspects of the code.
But this seems harder than it should be.
In this particular case, normal plotting packages can sometimes plot atomic positions with 3D scatter plots.
But then further algorithm visualization is hard (animation, drawing boxes, etc).</p>
<p>The <a href="http://vispy.org/VisPy">VisPy</a> project looks promising.
It contains three API levels </p>
<ol>
<li>
<code>gloo</code>- the lowest level API around OpenGL</li>
<li>
<code>scene</code>- uses a scene graph description</li>
<li>
<code>plot</code> - standard plotting interface</li>
</ol>
<p>The 'scene' interface is the appropriate abstraction level for our purposes.
Note this API is marked experimental and may change in the future.</p>
<h3>Pretty pictures</h3>
<p>Static screenshots (click for larger version)</p>
<p><a href="2015/md_screenshot2.png"><img alt="Screenshot2" src="2015/md_screenshot2_sm.png"></a>
<a href="2015/md_screenshot3.png"><img alt="Screenshot3" src="2015/md_screenshot3_sm.png"></a></p>
<p>And an animation (click for larger version)</p>
<p><a href="2015/animation.gif"><img alt="Screenshot3" src="2015/animation_sm.gif"></a></p>
<h3>Code</h3>
<p>The modified <code>comd.py</code> is <a href="https://gist.github.com/markdewing/28223759c2dbe24e1147">here</a>.
It should be a drop-in replacement for that file in the <a href="https://github.com/markdewing/multitevo/tree/master/CoMD/python/nsquared"><code>nsquared</code></a> version of the code.  The bulk of the visualization additions start around line 154.</p>
<p>The perceived speed of the simulation can vary.  Pure Python, even at the smallest system size, is too slow.
Using the <a href="http://markdewing.github.io/blog/posts/first-performance-improvements/">Numba-accelerated</a> loop makes it much faster.
However, for the smallest system, this feels 'too fast'.
Increasing the system size will slow it down (`-x 6 -y 6 -z 6' seems to work well on my system).
There are much better ways of adjusting the speed, but this is the most expedient.</p>
<p>The <code>-N</code> option specifies the number of steps (defaults to 100).  Set it to a larger value to run the animation longer.</p>
<p>During the run, press <code>s</code> to take a static screenshot (stored in <code>screenshot.png</code>).  Press 'a' key to start/stop saving
an animated segment (stored in <code>animation.gif</code>).   These features require that the <code>imageio</code> package is installed.</p>
<p>The <code>multiprocessing</code> package is used to run the simulation and the visualization event loop in separate processes.
Positions are passed from the simulation to the visualization via a Queue.
A Timer on the visualization side checks the queue for new positions periodically.</p>
<p>This code snippet uses the Marker visual element to display the center of each point.
This size is the size of the element on the screen, not the size in the scene (that is, elements don't change size when zooming)
The current size was chosen to easily see the motion of the atoms, not to accurately represent the atom's size.
Displaying a Sphere at each point would be more accurate, but is much slower.</p>
<h3>Summary</h3>
<p>I'm very pleased with VisPy.  It enabled live, interactive animation of atoms from a molecular dynamics code with
 a small amount code.
I expect extending this to visualize more complex algorithms and data structures should be be straightforward.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/more-with-numba/" class="u-url">More Performance With Numba</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/more-with-numba/" rel="bookmark">
            <time class="published dt-published" datetime="2015-11-13T10:30:00-06:00" itemprop="datePublished" title="2015-11-13 10:30">2015-11-13 10:30</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/more-with-numba/#disqus_thread" data-disqus-identifier="cache/posts/more-with-numba.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>Having acquired a shiny new <a href="http://markdewing.github.io/blog/posts/prototype-for-profiling-python/">profiler</a>, it's time to dig into the performance of the Numba version some more.</p>
<p>Picking up from the <a href="http://markdewing.github.io/blog/posts/improvements-in-comd-cell-method-performance/">previous optimizations</a>, I can't seem to reproduce the timing (47 μs/atom) in the that table.  Now I get 40 μs/atom.</p>
<h2>First step</h2>
<p>Run the profiler (<code>vmprofrun comd.py</code>) and display the results in KCacheGrind (<code>kcachegrind vmprof-20664.out</code>)</p>
<p>Sorting by self time, we see <code>getBoxFromCoord</code> at the top:</p>
<p><img alt="KCachegrind screenshot of functions sorted by self time" src="2015/profile1_by_self_sm.png"></p>
<p>Also a screen shot of the call graph - <code>getBoxFromCoord</code> gets called from two different places - <code>putAtomInBox</code> and <code>updateLinkCells</code>.</p>
<p><img alt="KCachegrind screenshot of call graph" src="2015/profile1_call_graph_sm.png"></p>
<p>To improve performance here, convert <code>getBoxFromCoord</code> to a free function and put all the attribute references into function arguments.</p>
<p>Before:</p>
<div class="code"><pre class="code literal-block">    <span class="k">def</span> <span class="nf">getBoxFromCoord</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">r</span><span class="p">):</span>
        <span class="n">ix</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">invBoxSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">iy</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">invBoxSize</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        <span class="n">iz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">r</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">invBoxSize</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getBoxFromTuple</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="n">iy</span><span class="p">,</span> <span class="n">iz</span><span class="p">)</span>
</pre></div>

<p>After:</p>
<div class="code"><pre class="code literal-block"><span class="nd">@numba</span><span class="o">.</span><span class="n">njit</span>
<span class="k">def</span> <span class="nf">getBoxFromCoordInner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">invBoxSize</span><span class="p">,</span> <span class="n">nLocalBoxes</span><span class="p">,</span> <span class="n">gs</span><span class="p">):</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">invBoxSize</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">iy</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">y</span><span class="o">*</span><span class="n">invBoxSize</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
    <span class="n">iz</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="n">z</span><span class="o">*</span><span class="n">invBoxSize</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">getBoxFromTupleInner</span><span class="p">(</span><span class="n">ix</span><span class="p">,</span> <span class="n">iy</span><span class="p">,</span> <span class="n">iz</span><span class="p">,</span> <span class="n">nLocalBoxes</span><span class="p">,</span> <span class="n">gs</span><span class="p">)</span>
</pre></div>

<p>(Changing the parameter <code>r</code> to individual components was not strictly necessary.)</p>
<p>And the call sites change (for example) from</p>
<div class="code"><pre class="code literal-block">        <span class="n">iBox</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">getBoxFromCoord</span><span class="p">([</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">])</span>
</pre></div>

<p>to</p>
<div class="code"><pre class="code literal-block">        <span class="n">iBox</span> <span class="o">=</span> <span class="n">getBoxFromCoordInner</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">invBoxSize</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">nLocalBoxes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gridSize</span><span class="p">)</span>
</pre></div>

<p>This improves performance to 20 μs/atom.</p>
<p>Repeating the same transformation for putAtomInBox gives 18.4 μs/atom.</p>
<h2>Second step</h2>
<p>Run the profiler again.  By self time, <code>loadAtomsBuffer</code> is at the top.  Let's look at that in context.
Sort by inclusive time, and we see that the parts of the call tree starting at <code>redistributeAtoms</code> take a significant amount of time.</p>
<p><img alt="KCachegrind screenshot of functions sorted by inclusive time" src="2015/profile2_by_incl_sm.png"></p>
<p><img alt="KCachegrind screenshot of call graph" src="2015/profile2_call_graph_sm.png"></p>
<p>This part of the code:</p>
<ul>
<li>Applies periodic boundary conditions</li>
<li>Moves atoms to a new cell</li>
<li>Packs atom into a buffer at source</li>
<li>Unpacks buffer into atom data structure at destination</li>
</ul>
<p>This packing/unpacking anticipates the parallel version, which transmits the buffer across processors.</p>
<p>A previous attempt at using numpy records did not work well (and ran into a serious performance regression with numpy 1.10).
This time I went with two buffers - one for integers, and one for floating point numbers.  This works better, and the
performance is now 10.2 μs/atom.</p>
<h2>More steps</h2>
<p>Continuing the process of profiling, and converting routines to be Numba friendly eventually reached a performance of 2.9 μs/atom.
(Wow, this is only about 30% slower than C.)</p>
<p>Modified code is <a href="https://gist.github.com/markdewing/8bd6bd8dbef8613004fe">here</a></p>
<p>The updated performance table is</p>
<table>
<thead><tr>
<th>Language/compiler  </th>
<th>Version   </th>
<th style="text-align: right;">Initial time</th>
<th style="text-align: right;">  Final time</th>
<th></th>
</tr></thead>
<tbody>
<tr>
<td>Python</td>
<td>2.7.10</td>
<td style="text-align: right;">1014</td>
<td style="text-align: right;">1014</td>
<td></td>
</tr>
<tr>
<td>PyPy</td>
<td>4.0</td>
<td style="text-align: right;">30</td>
<td style="text-align: right;">30</td>
<td></td>
</tr>
<tr>
<td>Cython</td>
<td>0.23.3</td>
<td style="text-align: right;">729</td>
<td style="text-align: right;">13</td>
<td></td>
</tr>
<tr>
<td>Julia</td>
<td>0.4.0-rc3</td>
<td style="text-align: right;">87</td>
<td style="text-align: right;">6.1</td>
<td></td>
</tr>
<tr>
<td>Numba</td>
<td>0.22.1</td>
<td style="text-align: right;">867</td>
<td style="text-align: right;">2.9</td>
<td>    New result</td>
</tr>
<tr>
<td>C (clang)</td>
<td>3.7</td>
<td style="text-align: right;">2.2</td>
<td style="text-align: right;">2.2</td>
<td></td>
</tr>
</tbody>
</table>
<p><br></p>
<div style="font-size:80%">
Times are all in μs/atom. System size is 4000 atoms.
Hardware is Xeon E5-2630 v3 @ 2.4 Ghz, OS is Ubuntu 12.04.
<br>
The 'Initial Time' column results from the minimal amount of code changes to get the compiler working.
<br>
The 'Final Time' is the time after tuning.
</div>
<p><br></p>
<p>Do note that the Cython, Julia, and Numba results reflect the amount of effort put into optimization.
Cython and Julia still need to be improved with the assistance of a profiler (or in Julia's case, a better viewer
for existing profile data).</p>
<h2>Summary</h2>
<p>Using a profiler to guide our optimization efforts has been very helpful.</p>
<p>The Numba results are really promising, but, in addition to creating ugly code, it required an amount of work
that I would not want to perform on a regular basis.    These transformations are fairly regular, so it should
be possible to incorporate them into Numba.  Alternately, if doing so in a safe manner inside the compiler is difficult,
some sort of automated AST transformation of the source should be possible.</p>
<p>As the optimization process proceeds on this code, increasing amount of time is being spent in the core routine, computeForce, (as it should), and we will need to move beyond a function-level profiler to look for optimization opportunities.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/updated-performance-with-pypy-40/" class="u-url">Performance Updates with PyPy 4.0</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/updated-performance-with-pypy-40/" rel="bookmark">
            <time class="published dt-published" datetime="2015-11-04T15:39:00-06:00" itemprop="datePublished" title="2015-11-04 15:39">2015-11-04 15:39</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/updated-performance-with-pypy-40/#disqus_thread" data-disqus-identifier="cache/posts/updated-performance-with-pypy-40.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p>The PyPy team recently released version <a href="http://morepypy.blogspot.com/2015/10/pypy-400-released-jit-with-simd.html">4.0</a>
(The jump in version number is to reduce confusion with the Python version supported.)
One of the features is improved performance.</p>
<p>But first, an issue with reporting accurate timings with this version of CoMD should be addressed. The initial iteration contains overhead from tracing and JIT compilation (Cython and Numba have the same issue).
For this example we are concerned with the steady-state timing, so the time for the first iteration should be excluded.
I've added a '--skip' parameter to the CoMD code (default: 1) that skips the first <code>printRate</code> steps (default: 10) in computing the overall average update rate at the end.</p>
<p>Now the table with the most recent performance numbers  (from <a href="http://markdewing.github.io/blog/posts/improvements-in-comd-cell-method-performance/">this post</a> ), updated with PyPy 4.0 results:</p>
<p>| Language/compiler   | Version   | Time|
|-------------------|--------------|--------------:|------------:|
| Python            | 2.7.10       |  1014          | |
| PyPy              | 2.6.1        |    96         | |
| Numba             | 0.21.0       |     47     | |
| PyPy              | 4.0          |    30         |      New result |
| Cython            | 0.23.3       |     13     | |
| Julia             | 0.4.0-rc3    |    6.1     | |
| C                 | 4.8.2        |    2.3          | |</p>
<p><br>
Times are all in μs/atom. System size is 4000 atoms.
Hardware is Xeon E5-2630 v3 @ 2.4 Ghz, OS is Ubuntu 12.04.
<br></p>
<p>The new release of PyPy also includes some SIMD vectorization support (<code>--jit vec=1</code> or <code>--jit vec_all=1</code>).  Neither of these provided any improvement in performance on this code.   Not too surprising given the vectorization support is new, and the code contains
conditionals in the inner loop.</p>
<p>PyPy 4.0 gives a very good 34x performance improvement over bare Python, and 3x improvement over the previous release (2.6.1).
PyPy is attractive here in that no modifications made to the source.  (Both Cython and Numba required source changes)</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/prototype-for-profiling-python/" class="u-url">Prototype for Profiling Python</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                Mark Dewing
            </span></p>
            <p class="dateline">
            <a href="posts/prototype-for-profiling-python/" rel="bookmark">
            <time class="published dt-published" datetime="2015-10-12T12:20:00-05:00" itemprop="datePublished" title="2015-10-12 12:20">2015-10-12 12:20</time></a>
            </p>
                <p class="commentline">
    
    <a href="posts/prototype-for-profiling-python/#disqus_thread" data-disqus-identifier="cache/posts/prototype-for-profiling-python.html">Comments</a>


        </p>
</div>
    </header><div class="e-content entry-content">
    <p><a href="posts/towards-profiling-accelerated-python/">Last post</a> covered some technical background using vmprof to profile Python with compiled or JIT'ed extensions.
Now I've created a prototype that can convert the output to callgrind format so it can be viewed with <a href="http://kcachegrind.sourceforge.net/html/Home.html">KCachegrind</a>.</p>
<p>To install the prototype using the Anaconda distribution:</p>
<ol>
<li>Create a new environment (if you do not use a new environment, these packages may conflict with an existing Numba install): <code>conda create -n profiling python numpy</code>
</li>
<li>Switch to the new environment: <code>source activate profiling</code>
</li>
<li>Install prototype versions of Numba and llvmlite: <code>conda install -c https://conda.anaconda.org/mdewing numba-profiling</code>
</li>
<li>Install prototype version of vmprof: <code>conda install -c https://conda.anaconda.org/mdewing vmprof-numba</code>
</li>
<li>Make sure libunwind is installed.  (On Ubuntu <code>apt-get install libunwind8-dev</code>.)
(On Ubuntu, it must be the -dev version.  If not installed, the error message when trying to run vmprof is <code>ImportError: libunwind.so.8: cannot open shared object file: No such file or directory</code>)</li>
<li>Install KCachegrind (On Ubuntu, <code>apt-get install kcachegrind</code>)</li>
</ol>
<p>There is a wrapper (<code>vmprofrun</code>) that automates the running and processing steps.
To use it, run <code>vmprofrun &lt;target python script&gt; [arguments to the python script]</code>. 
(No need to specify <code>python</code> - that gets added to the command line automatically.)
By default it will output <code>vmprof-&lt;pid&gt;.out</code>, which can be viewed in KCachegrind.</p>
<p>Underneath, the <code>vmprofrun</code> tool saves the vmprof output during the run to <code>out.vmprof</code>. After the run, it automatically copies the <code>/tmp/perf-&lt;pid&gt;.map</code> file to the current directory (if running under Numba).
It moves <code>out.vmprof</code> to <code>out-&lt;pid&gt;.vmprof</code>.
Finally it runs <code>vmproftocallgrind</code> using these files as input.</p>
<h4>Limitations</h4>
<ol>
<li>Only works on 64-bit Linux</li>
<li>Function-level profiles only - no line information (for either python or native code)</li>
<li>Sometimes the profiling hangs during the run - kill the process and try again.</li>
<li>Works with Python 2.7 or 3.4</li>
<li>Not well validated or tested yet</li>
<li>It does not work well yet with the existing vmprof web visualization and CLI tools.</li>
</ol>
<p>Other notes:</p>
<ul>
<li>The stack dump tool will process the stacks to remove the Python interpreter frames.</li>
<li>By default the Numba <code>Dispatcher_call</code> level is removed.  Otherwise the call graph in KCachegrind gets tangled by all the call paths running through this function.</li>
<li>It should work with C extensions and Cython as well.</li>
</ul>
</div>
    </article>
</div>

        <ul class="pager postindexpager clearfix">
<li class="next"><a href="index-1.html" rel="next">Older posts</a></li>
        </ul>
<script>var disqus_shortname="journeytothecenterofthecomputer";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><!--End of body content--><footer id="footer">
            Contents © 2024         <a href="mailto:markdewing%20(at)%20gmail%20(dot)%20com">Mark Dewing</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
